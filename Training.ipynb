{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8JSFMr5dd8C",
    "outputId": "8d7da73e-5f4e-48b9-c048-7b489ece1a21"
   },
   "outputs": [],
   "source": [
    "import opennmt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "import pyonmttok\n",
    "from opennmt.utils import checkpoint as checkpoint_util\n",
    "from pyonmttok import SentencePieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bYaTz9YDpqd"
   },
   "outputs": [],
   "source": [
    "def count_weights(model):\n",
    "  trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "  non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "\n",
    "  print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "  print('Trainable params: {:,}'.format(trainable_count))\n",
    "  print('Non-trainable params: {:,}'.format(non_trainable_count))\n",
    "\n",
    "def compute_scores(runner, features_filename, labels_filename, pred_filename, include_ppl=False, include_ter=False):\n",
    "  runner.infer(features_filename, pred_filename)\n",
    "\n",
    "  dot_idx = pred_filename.index('.')\n",
    "  base_pred_name = pred_filename[0:dot_idx]\n",
    "  dot_idx = labels_filename.index('.')\n",
    "  base_model_name = labels_filename[0:dot_idx]\n",
    "  pred_filename = detokenize_data(base_pred_name, base_model_name)\n",
    "  detokenized_labels_filename = detokenize_data(base_model_name, base_model_name)\n",
    "  preds = []\n",
    "  truth = []\n",
    "  with open(pred_filename) as f:\n",
    "    preds = f.readlines()\n",
    "\n",
    "  with open(detokenized_labels_filename) as f:\n",
    "    truth = f.readlines()\n",
    "\n",
    "  scores = dict()\n",
    "  if include_ppl:\n",
    "    scores = runner.evaluate(\n",
    "        features_file=features_filename,\n",
    "        labels_file=labels_filename)\n",
    "  \n",
    "  bleu = sacrebleu.corpus_bleu(preds, [truth])\n",
    "  scores.update({'bleu': bleu.score})\n",
    "  if include_ter:\n",
    "    ter = sacrebleu.corpus_ter(preds, [truth])\n",
    "    scores.update({'ter': ter.score})\n",
    "  \n",
    "  return scores\n",
    "\n",
    "def detokenize(model_basename, tokenized_basename):\n",
    "  model_path = os.path.join(\"sentencepiece_models\", model_basename + \".model\")\n",
    "  vocabulary_path = os.path.join(\"sentencepiece_models\", f\"{model_basename}.vocab\")\n",
    "  detokenizer = SentencePieceTokenizer(model_path=model_path,\n",
    "                                     vocabulary_path=vocabulary_path,)\n",
    "  \n",
    "  with open(f\"{tokenized_basename}.tok\") as f:\n",
    "    with open(f\"{tokenized_basename}.txt\", mode=\"w\") as fout:\n",
    "      for line in f.readlines():\n",
    "        fout.write(detokenizer.detokenize(line.strip().split(\" \")) + \"\\n\")\n",
    "\n",
    "  return f\"{tokenized_basename}.txt\"\n",
    "\n",
    "def tokenize(input_file, basename):\n",
    "  model_path = os.path.join(\"sentencepiece_models\", f\"{basename}.model\")\n",
    "  vocabulary_path = os.path.join(\"sentencepiece_models\", f\"{basename}.vocab\")\n",
    "  tokenizer = SentencePieceTokenizer(model_path=model_path,\n",
    "                                     vocabulary_path=vocabulary_path,)\n",
    "  \n",
    "  with open(os.path.join(f\"{input_file}\")) as f:\n",
    "    with open(os.path.join(f\"{basename}.tok\"), mode=\"w\") as fout:\n",
    "      for line in f.readlines():\n",
    "        if line.strip():\n",
    "          fout.write(\" \".join(tokenizer.tokenize(line)[0]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5b-2BgLedXC"
   },
   "outputs": [],
   "source": [
    "# Build vocab (uses SentencePiece)\n",
    "# source = catalan   (ca)\n",
    "# pivot  = spanish   (es)\n",
    "# target = italian  (it)\n",
    "\n",
    "!onmt-build-vocab --sentencepiece model_type=bpe --size 32000 --save_vocab sentencepiece_models/src src_pvt_data/src_train.txt\n",
    "!onmt-build-vocab --sentencepiece model_type=bpe --size 32000 --save_vocab sentencepiece_models/pvt_src src_pvt_data/pvt_src_train.txt\n",
    "\n",
    "!onmt-build-vocab --sentencepiece model_type=bpe --size 32000 --save_vocab sentencepiece_models/tgt pvt_tgt_data/tgt_train.txt\n",
    "!onmt-build-vocab --sentencepiece model_type=bpe --size 32000 --save_vocab sentencepiece_models/pvt_tgt pvt_tgt_data/pvt_tgt_train.txt\n",
    "\n",
    "!onmt-build-vocab --sentencepiece model_type=bpe --size 32000 --save_vocab sentencepiece_models/src_tgt src_tgt_data/src_tgt_train.txt\n",
    "!onmt-build-vocab --sentencepiece model_type=bpe --size 32000 --save_vocab sentencepiece_models/tgt_src src_tgt_data/tgt_src_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "J7kTzUGY531m",
    "outputId": "54a9a4a3-94c3-4582-af17-1d2f33566f67"
   },
   "outputs": [],
   "source": [
    "tokenize(\"src_tgt_test.txt\",\"src_tgt_test\")\n",
    "tokenize(\"src_tgt_train.txt\",\"src_tgt_train\")\n",
    "tokenize(\"src_tgt_val.txt\",\"src_tgt_val\")\n",
    "tokenize(\"tgt_src_test.txt\",\"tgt_src_test\")\n",
    "tokenize(\"tgt_src_train.txt\",\"tgt_src_train\")\n",
    "tokenize(\"tgt_src_val.txt\",\"tgt_src_val\")\n",
    "\n",
    "tokenize(\"src_test.txt\",\"src_test\")\n",
    "tokenize(\"src_train.txt\",\"src_train\")\n",
    "tokenize(\"src_val.txt\",\"src_val\")\n",
    "tokenize(\"pvt_src_test.txt\",\"pvt_src_test\")\n",
    "tokenize(\"pvt_src_train.txt\",\"pvt_src_train\")\n",
    "tokenize(\"pvt_src_val.txt\",\"pvt_src_val\")\n",
    "\n",
    "tokenize(\"pvt_tgt_test.txt\",\"pvt_tgt_test\")\n",
    "tokenize(\"pvt_tgt_train.txt\",\"pvt_tgt_train\")\n",
    "tokenize(\"pvt_tgt_val.txt\",\"pvt_tgt_val\")\n",
    "tokenize(\"tgt_test.txt\",\"tgt_test\")\n",
    "tokenize(\"tgt_train.txt\",\"tgt_train\")\n",
    "tokenize(\"tgt_val.txt\",\"tgt_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk7pKHsaho23"
   },
   "outputs": [],
   "source": [
    "config_src_pvt = {\n",
    "    \"model_dir\": \"src_pvt_model/\",\n",
    "    \"data\": {\n",
    "        \"train_features_file\": \"src_pvt_data/src_train.tok/\",\n",
    "        \"train_labels_file\": \"src_pvt_data/pvt_src_train.tok/\",\n",
    "        \"eval_features_file\": \"src_pvt_data/src_val.tok/\",\n",
    "        \"eval_labels_file\": \"src_pvt_data/pvt_src_val.tok/\",\n",
    "        \"source_vocabulary\": \"sentencepiece_models/src.vocab/\",\n",
    "        \"target_vocabulary\": \"sentencepiece_models/pvt_src.vocab/\",\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"max_step\": 25000,\n",
    "        \"save_checkpoints_steps\": 500,\n",
    "        \"keep_checkpoint_max\": 2,\n",
    "    },\n",
    "    \"eval\": {\n",
    "        \"save_eval_predictions\": True,\n",
    "        \"steps\": 50000,\n",
    "        \"max_exports_to_keep\": 2,\n",
    "        \"early_stopping\": {\n",
    "            \"metric\": \"loss\",\n",
    "            \"min_improvement\": 0.1,\n",
    "            \"steps\": 100,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "config_pvt_tgt = {\n",
    "    \"model_dir\": \"/content/pvt_tgt_model/\",\n",
    "    \"data\": {\n",
    "        \"train_features_file\": \"/content/pvt_tgt_data/pvt_tgt_train.tok/\",\n",
    "        \"train_labels_file\": \"/content/pvt_tgt_data/tgt_train.tok/\",\n",
    "        \"eval_features_file\": \"/content/pvt_tgt_data/pvt_tgt_val.tok/\",\n",
    "        \"eval_labels_file\": \"/content/pvt_tgt_data/tgt_val.tok/\",\n",
    "        \"source_vocabulary\": \"/content/sentencepiece_models/pvt_tgt.vocab/\",\n",
    "        \"target_vocabulary\": \"/content/sentencepiece_models/tgt.vocab/\",\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"max_step\": 25000,\n",
    "        \"save_checkpoints_steps\": 500,\n",
    "        \"keep_checkpoint_max\": 2,\n",
    "    },\n",
    "    \"eval\": {\n",
    "        \"save_eval_predictions\": True,\n",
    "        \"steps\": 50000,\n",
    "        \"max_exports_to_keep\": 2,\n",
    "        \"early_stopping\": {\n",
    "            \"metric\": \"loss\",\n",
    "            \"min_improvement\": 0.1,\n",
    "            \"steps\": 100,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "config_src_tgt = {\n",
    "    \"model_dir\": \"/content/src_tgt_model/\",\n",
    "    \"data\": {\n",
    "        \"train_features_file\": \"/content/src_tgt_data/src_tgt_train.tok\",\n",
    "        \"train_labels_file\": \"/content/src_tgt_data/tgt_src_train.tok\",\n",
    "        \"eval_features_file\": \"/content/src_tgt_data/src_tgt_val.tok\",\n",
    "        \"eval_labels_file\": \"/content/src_tgt_data/tgt_src_val.tok\",\n",
    "        \"source_vocabulary\": \"/content/sentencepiece_models/src_tgt.vocab\",\n",
    "        \"target_vocabulary\": \"/content/sentencepiece_models/tgt_src.vocab\",\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"max_step\": 25000,\n",
    "        \"save_checkpoints_steps\": 500,\n",
    "        \"keep_checkpoint_max\": 2,\n",
    "    },\n",
    "    \"eval\": {\n",
    "        \"save_eval_predictions\": True,\n",
    "        \"steps\": 50000,\n",
    "        \"max_exports_to_keep\": 2,\n",
    "        \"early_stopping\": {\n",
    "            \"metric\": \"loss\",\n",
    "            \"min_improvement\": 0.1,\n",
    "            \"steps\": 100,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "config_baseline = {\n",
    "    \"model_dir\": \"/content/baseline_model/\",\n",
    "    \"data\": {\n",
    "        \"train_features_file\": \"/content/src_tgt_data/src_tgt_train.tok/\",\n",
    "        \"train_labels_file\": \"/content/src_tgt_data/tgt_src_train.tok/\",\n",
    "        \"eval_features_file\": \"/content/src_tgt_data/src_tgt_val.tok/\",\n",
    "        \"eval_labels_file\": \"/content/src_tgt_data/tgt_src_val.tok/\",\n",
    "        \"source_vocabulary\": \"/content/sentencepiece_models/src_tgt.vocab/\",\n",
    "        \"target_vocabulary\": \"/content/sentencepiece_models/tgt_src.vocab/\",\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"max_step\": 25000,\n",
    "        \"save_checkpoints_steps\": 500,\n",
    "        \"keep_checkpoint_max\": 2,\n",
    "    },\n",
    "    \"eval\": {\n",
    "        \"save_eval_predictions\": True,\n",
    "        \"steps\": 50000,\n",
    "        \"max_exports_to_keep\": 2,\n",
    "        \"early_stopping\": {\n",
    "            \"metric\": \"loss\",\n",
    "            \"min_improvement\": 0.1,\n",
    "            \"steps\": 100,\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KM2gDhAv_Ahd"
   },
   "outputs": [],
   "source": [
    "learning_rate = opennmt.schedules.NoamDecay(scale=2.0, model_dim=512, warmup_steps=8000)\n",
    "optimizer = tfa.optimizers.LazyAdam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSbSfQRMi73X"
   },
   "outputs": [],
   "source": [
    "# Training source-pivot model\n",
    "src_pvt_model = opennmt.models.TransformerBase()\n",
    "src_pvt_runner = opennmt.Runner(src_pvt_model, config_src_pvt, auto_config=True)\n",
    "sp_config = src_pvt_runner._finalize_config(training=True)\n",
    "\n",
    "src_pvt_runner.train(num_devices=1, with_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rv_Ldfhi-an"
   },
   "outputs": [],
   "source": [
    "# Training pivot-target model\n",
    "pvt_tgt_model = opennmt.models.TransformerBase()\n",
    "pvt_tgt_runner = opennmt.Runner(pvt_tgt_model, config_pvt_tgt, auto_config=True)\n",
    "pt_config = pvt_tgt_runner._finalize_config(training=True)\n",
    "\n",
    "pvt_tgt_runner.train(num_devices=1, with_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSAiz8rKJ0bw"
   },
   "outputs": [],
   "source": [
    "# Restore both models weights\n",
    "src_pvt_model.initialize(data_config=sp_config['data'], params=sp_config['params'])\n",
    "src_pvt_model.create_variables(optimizer=optimizer)\n",
    "\n",
    "pvt_tgt_model.initialize(data_config=pt_config['data'], params=pt_config['params'])\n",
    "pvt_tgt_model.create_variables(optimizer=optimizer)\n",
    "\n",
    "checkpoint_path = sp_config['model_dir']\n",
    "checkpoint = checkpoint_util.Checkpoint.from_config(sp_config, src_pvt_model, optimizer=optimizer)\n",
    "checkpoint.restore(checkpoint_path=checkpoint_path, weights_only=True)\n",
    "\n",
    "checkpoint_path = pt_config['model_dir']\n",
    "checkpoint = checkpoint_util.Checkpoint.from_config(pt_config, pvt_tgt_model, optimizer=optimizer)\n",
    "checkpoint.restore(checkpoint_path=checkpoint_path, weights_only=True)\n",
    "\n",
    "count_weights(src_pvt_model)\n",
    "count_weights(pvt_tgt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utqcEQnWXNXk"
   },
   "outputs": [],
   "source": [
    "# Transfer weights to src_tgt_model\n",
    "src_tgt_model = opennmt.models.TransformerBase()\n",
    "src_tgt_runner = opennmt.Runner(src_tgt_model, config_src_tgt, auto_config=True)\n",
    "st_config = src_tgt_runner._finalize_config(training=True)\n",
    "\n",
    "src_tgt_model.initialize(data_config=st_config['data'], params=st_config['params'])\n",
    "src_tgt_model.create_variables(optimizer=optimizer)\n",
    "\n",
    "src_tgt_model.encoder = src_pvt_model.encoder\n",
    "src_tgt_model.decoder = pvt_tgt_model.decoder\n",
    "\n",
    "new_checkpoint = checkpoint_util.Checkpoint.from_config(st_config, src_tgt_model, optimizer=optimizer)\n",
    "new_checkpoint.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9P6AnVrZHRBQ",
    "outputId": "ed753dad-35b4-462a-8465-7275ddb4457d"
   },
   "outputs": [],
   "source": [
    "# Training source-target model (using pretrained models)\n",
    "src_tgt_model = opennmt.models.TransformerBase()\n",
    "src_tgt_runner = opennmt.Runner(src_tgt_model, config_src_tgt, auto_config=True)\n",
    "st_config = src_tgt_runner._finalize_config(training=True)\n",
    "src_tgt_runner.train(num_devices=1, with_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7H76tXv2mr_"
   },
   "outputs": [],
   "source": [
    "# Training source-target model (using no models)\n",
    "baseline_model = opennmt.models.TransformerBase()\n",
    "baseline_runner = opennmt.Runner(baseline_model, config_baseline, auto_config=True)\n",
    "\n",
    "baseline_runner.train(num_devices=1, with_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzgD5BPpNQAF"
   },
   "outputs": [],
   "source": [
    "# Compute scores\n",
    "baseline_scores = compute_scores(\n",
    "    runner=baseline_runner,\n",
    "    features_filename=\"/content/src_tgt_data/src_tgt_test.txt\",\n",
    "    labels_filename=\"/content/src_tgt_data/tgt_src_test.txt\",\n",
    "    pred_filename=\"/content/baseline_pred.txt\")\n",
    "\n",
    "pivot_based_tl_scores = compute_scores(\n",
    "    runner=src_tgt_runner,\n",
    "    features_filename=\"/content/src_tgt_data/src_tgt_test.txt\",\n",
    "    labels_filename=\"/content/src_tgt_data/tgt_src_test.txt\",\n",
    "    pred_filename=\"/content/src_to_tgt_pred.txt\")\n",
    "\n",
    "print(f\"============ Baseline Source-Target NMT Evaluation ============\\n {baseline_scores}\")\n",
    "print(f\"============ Pretrain Source-Target NMT Evaluation ============\\n {pivot_based_tl_scores}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "V_P9hZPqPPZ0"
   ],
   "machine_shape": "hm",
   "name": "OpenNMT Capstone Training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
